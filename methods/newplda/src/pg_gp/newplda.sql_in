m4_include(`SQLCommon.m4')

CREATE OR REPLACE FUNCTION
	MADLIB_SCHEMA.__newplda_random_assign(word_cnt int4, num_topic int4)
RETURNS int4[] AS 'MODULE_PATHNAME', 'randomAssign' LANGUAGE C STRICT;

CREATE OR REPLACE FUNCTION
	MADLIB_SCHEMA.__newplda_gibbs_sample(topics int4[], count_d_z int4[], count_w_z int4[],
                        count_z int4[], alpha float, beta float)
RETURNS int4[]
AS 'MODULE_PATHNAME', 'sampleNewTopic' LANGUAGE C STRICT;

-- Using encoded array to transfer state should be more efficient
-- begin: expeirment with window function to transfer states between rows - we can update doc_topic and word_topic matrixes immedidately after sampling a new topic for each word
-- Encoded int4 array for storing STATE info:
--	docid int4
--	wordid int4
--	tcount int4
--	topics int4[]
--	corpus_topic int4[]
--	doc_topic int4[]
--	word_topic int4[]
--	wlist int4[]
CREATE OR REPLACE FUNCTION
	MADLIB_SCHEMA.__newplda_gibbs_sfunc_fast(state int[], docid int4, wordid int4, topics int4[], count_d_z int4[], count_w_z int4[],
                        count_z int4[], alpha float, beta float, vocab_size int4, num_topic int4)
RETURNS int4[] 
AS 'MODULE_PATHNAME', 'sFunc4GibbsWFuncFast' LANGUAGE C;

-- Encoded int4 array for storing FINAL STATE info:
--	docid int4,
--	wordid int4,
--	topics int4[],
CREATE OR REPLACE FUNCTION
	MADLIB_SCHEMA.__newplda_gibbs_ffunc_fast(state int4[])
RETURNS int4[]
AS 'MODULE_PATHNAME', 'fFunc4GibbsWFuncFast' LANGUAGE C STRICT;

--docid int4, wordid int4, topics int4[], 
--count_d_z int4[], count_w_z int4[], count_z int4[],
--alpha float, beta float, vocab_size int4, num_topic int4
DROP AGGREGATE IF EXISTS MADLIB_SCHEMA.__newplda_gibbs_wfunc_fast(int4, int4, int4[], int4[], int4[], int4[], float, float, int4, int4);
CREATE AGGREGATE MADLIB_SCHEMA.__newplda_gibbs_wfunc_fast(int4, int4, int4[], 
			int4[], int4[], int4[],
			float, float, int4, int4)
(
        sfunc = MADLIB_SCHEMA.__newplda_gibbs_sfunc_fast,
	finalfunc = MADLIB_SCHEMA.__newplda_gibbs_ffunc_fast,
        stype = int4[] 
);
-- end 

-- Using composity type to pass state is very slow and inefficient
-- begin: expeirment with window function to transfer states between rows - we can update doc_topic and word_topic matrixes immedidately after sampling a new topic for each word
DROP TYPE IF EXISTS MADLIB_SCHEMA.__newplda_gibbs_state CASCADE;
CREATE TYPE MADLIB_SCHEMA.__newplda_gibbs_state
	AS (
		docid int4,
		wordid int4,
		topics int4[],
		corpus_topic int4[],
		doc_topic int4[],
		word_topic int4[],
		word_list int4[]
	);
CREATE OR REPLACE FUNCTION
	MADLIB_SCHEMA.__newplda_gibbs_sfunc(state MADLIB_SCHEMA.__newplda_gibbs_state, docid int4, wordid int4, topics int4[], count_d_z int4[], count_w_z int4[],
                        count_z int4[], alpha float, beta float, vocab_size int4, num_topic int4)
RETURNS MADLIB_SCHEMA.__newplda_gibbs_state
AS 'MODULE_PATHNAME', 'sFunc4GibbsWFunc' LANGUAGE C;

DROP TYPE IF EXISTS MADLIB_SCHEMA.__newplda_gibbs_final_state CASCADE;
CREATE TYPE MADLIB_SCHEMA.__newplda_gibbs_final_state
	AS (
		docid int4,
		wordid int4,
		topics int4[]
	);
CREATE OR REPLACE FUNCTION
	MADLIB_SCHEMA.__newplda_gibbs_ffunc(state MADLIB_SCHEMA.__newplda_gibbs_state)
RETURNS MADLIB_SCHEMA.__newplda_gibbs_final_state
AS 'MODULE_PATHNAME', 'fFunc4GibbsWFunc' LANGUAGE C STRICT;

--docid int4, wordid int4, topics int4[], 
--count_d_z int4[], count_w_z int4[], count_z int4[],
--alpha float, beta float, vocab_size int4, num_topic int4
DROP AGGREGATE IF EXISTS MADLIB_SCHEMA.newplda_gibbs_wfunc(int4, int4, int4[], int4[], int4[], int4[], float, float, int4, int4);
CREATE AGGREGATE MADLIB_SCHEMA.__newplda_gibbs_wfunc(int4, int4, int4[], 
			int4[], int4[], int4[],
			float, float, int4, int4)
(
        sfunc = MADLIB_SCHEMA.__newplda_gibbs_sfunc,
	finalfunc = MADLIB_SCHEMA.__newplda_gibbs_ffunc,
        stype = MADLIB_SCHEMA.__newplda_gibbs_state 
);
-- end 
----

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.__newplda_sum_topic_count_sfunc(state int4[], topics int4[], num_topic int4)
RETURNS int4[] 
AS 'MODULE_PATHNAME', 'sumTopicCount' LANGUAGE C;

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.__newplda_sum_topic_count_prefunc(state1 int4[], state2 int4[])
RETURNS int4[] 
AS 'MODULE_PATHNAME', 'intArrayAdd' LANGUAGE C STRICT;

DROP AGGREGATE IF EXISTS MADLIB_SCHEMA.newplda_sum_topic_count_agg(int4[], int4);
CREATE AGGREGATE MADLIB_SCHEMA.newplda_sum_topic_count_agg(int4[], int4)
(
        sfunc = MADLIB_SCHEMA.__newplda_sum_topic_count_sfunc,
	m4_ifdef(`__GREENPLUM__', `prefunc = MADLIB_SCHEMA.__newplda_sum_topic_count_prefunc,')
        stype = int4[]
);

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.__newplda_log_likelihood_sfunc(state float8, counts int4[], hyper float8)
RETURNS float8 
AS 'MODULE_PATHNAME', 'logLikelihood' LANGUAGE C STRICT;

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.__float_add(state1 float8, state2 float8)
RETURNS float8 
AS $$
	return state1 + state2
$$ LANGUAGE PLPYTHONU;

DROP AGGREGATE IF EXISTS MADLIB_SCHEMA.newplda_log_likelihood_agg(int4[], float8);
CREATE AGGREGATE MADLIB_SCHEMA.newplda_log_likelihood_agg(int4[], float8)
(
        sfunc = MADLIB_SCHEMA.__newplda_log_likelihood_sfunc,
	m4_ifdef(`__GREENPLUM__', `prefunc = MADLIB_SCHEMA.__float_add,')
        stype = float8,
	initcond = '0.0'
);

DROP TYPE IF EXISTS MADLIB_SCHEMA.newplda_word_prob CASCADE;
CREATE TYPE MADLIB_SCHEMA.newplda_word_prob AS (word text, prob float8);

CREATE FUNCTION MADLIB_SCHEMA.newplda_get_topic_desc(topicid int4, label text, top int4, beta float8)
RETURNS SETOF MADLIB_SCHEMA.newplda_word_prob AS $$
	total = plpy.execute('SELECT SUM(topics[%d] + %f) total FROM word_topic_%s' % (topicid, beta, label))[0]['total']
	return plpy.execute("""SELECT word, (topics[%d] + %f)/%f AS prob 
		FROM word_topic_%s AS word_topic, vocab_%s AS vocab 
		WHERE word_topic.wordid = vocab.wordid 
		ORDER BY prob DESC LIMIT %d""" % (topicid, beta, total, label, label, top))
$$ LANGUAGE plpythonu;


CREATE FUNCTION MADLIB_SCHEMA.newplda_get_topic_desc_all(num_topic int4, label text, top int4, beta float8)
RETURNS text AS $$
	plpy.execute('DROP TABLE IF EXISTS topic_desc_%s' % (label))
	plpy.execute('CREATE TABLE topic_desc_%s(topicid int4, word text, prob float8)' % (label) \
		m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (topicid)"'))
	for topicid in xrange(1, num_topic + 1):
		total = plpy.execute('SELECT SUM(topics[%d] + %f) total FROM word_topic_%s' % (topicid, beta, label))[0]['total']
		plpy.execute("""INSERT INTO topic_desc_%s 
			SELECT %d, word, (topics[%d] + %f)/%f AS prob 
			FROM word_topic_%s AS word_topic, vocab_%s AS vocab
			WHERE word_topic.wordid = vocab.wordid ORDER BY prob DESC LIMIT %d""" % \
			(label, topicid, topicid, beta, total, label, label, top))
	return "run 'SELECT * FROM topic_desc_%s order by topicid ASC, prob desc' to show results" % (label)
$$ LANGUAGE plpythonu;

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.newplda_get_doc_topic_dist(topics int4[], alpha float8)
RETURNS float8[] AS $$
	global topics

	total = sum(topics)
	total += alpha * len(topics)
	topics = map(lambda r: (float(r)+alpha)/total, topics)
	return topics 
$$ LANGUAGE plpythonu;


CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.newplda_get_doc_topic_main(topics int4[], alpha float8)
RETURNS int4[] AS $$
	global topics

	total = sum(topics)
	total += alpha * len(topics)
	topics = map(lambda r: (float(r)+alpha)/total, topics)
	idx = range(len(topics))
	idx.sort(key=lambda r: topics[r], reverse=True)
	return idx[:10] 
$$ LANGUAGE plpythonu;

CREATE OR REPLACE FUNCTION
MADLIB_SCHEMA.newplda_pred(dataset text, num_topic int4, alpha float8, beta float8, label text)
RETURNS text AS $$
	import plpy
	import random
	import time

	class PLDA:
		def __init__(self, dataset, num_topic, alpha, beta, label = ''):
			label = label.replace('.', '_')
			self.dataset = dataset
			self.num_topic = num_topic
			self.alpha = alpha
			self.beta = beta

			if label.strip() != '':
				label = '_' + label.strip()
			self.word_topic = 'word_topic' + label
			
			self.doc_topic = 'doc_topic' + label + '_pred'
			plpy.execute('DROP TABLE IF EXISTS %s' % self.doc_topic)
			plpy.execute('CREATE TABLE %s(docid int4, topics int4[]) ' % (self.doc_topic) \
				m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (docid)"'))

			str_sql = 'SELECT sum(topics) topics FROM %s'
			count_z_t = plpy.execute(str_sql % (self.word_topic))
        		if (count_z_t.nrows() <> 1):
				plpy.error("error: count_z is not of the expected form")
			self.count_z = count_z_t[0]['topics']

			plpy.execute('DROP TABLE IF EXISTS doc_word_topic_0')
			plpy.execute('CREATE TABLE doc_word_topic_0(docid int4, wordid int4, topics int4[])' \
				m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (docid)"'))
			plpy.execute('DROP TABLE IF EXISTS doc_word_topic_1')
			plpy.execute('CREATE TABLE doc_word_topic_1(docid int4, wordid int4, topics int4[])' \
				m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (docid)"'))

		def init_random(self):
			stime = time.time()
			plpy.info('initializing topics randomly...')
			plpy.execute('TRUNCATE TABLE doc_word_topic_0');
			plpy.execute("""INSERT INTO doc_word_topic_0
				SELECT docid, wordid, MADLIB_SCHEMA.__newplda_random_assign(count, %d) 
				FROM %s""" % (self.num_topic, self.dataset))
			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def comp_doc_topic(self, it):
			stime = time.time()
			plpy.info('\t\tcomputing per-document topic distribution...')
			plpy.execute('TRUNCATE TABLE %s' % (self.doc_topic))
			plpy.execute("""INSERT INTO %s 
				SELECT docid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) 
				FROM doc_word_topic_%d 
				GROUP BY docid""" % (self.doc_topic, self.num_topic, it % 2))
			etime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def iteration(self, it):  
			stime = time.time()
			plpy.info('iteration [%d]....' % (it))

			sstime = time.time()
			plpy.info('\t\tsampling new topics...')
			plpy.execute('TRUNCATE TABLE doc_word_topic_%d' % (it % 2))
			plpy.execute("""INSERT INTO doc_word_topic_%d
				SELECT dwz.docid, dwz.wordid, 
					MADLIB_SCHEMA.__newplda_gibbs_sample(dwz.topics, dz.topics, wz.topics, array[%s], %f, %f)
				FROM doc_word_topic_%d AS dwz, %s AS dz, %s AS wz
				WHERE dwz.docid = dz.docid and dwz.wordid = wz.wordid""" % \
				(it % 2, str(self.count_z)[1:-1].replace('L', ''), self.alpha, \
				self.beta, 1 - it % 2, self.doc_topic, self.word_topic)) 
			eetime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (eetime - sstime))

			self.comp_doc_topic(it)
			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))
		
		def run(self):
			stime = time.time()
			# initialize
			self.init_random()
			self.comp_doc_topic(0)

			plpy.info('start predicting process...')
			for it in range(1, 20):
				self.iteration(it)
			etime = time.time()
			plpy.info('finished, time elapsed: %.2f seconds' % (etime - stime))

	plda = PLDA(dataset, num_topic, alpha, beta, label)
	plda.run()
	return 'succeeds';
$$ LANGUAGE plpythonu;

CREATE OR REPLACE FUNCTION
MADLIB_SCHEMA.newplda_train(dataset text, num_topic int4, num_iter int4, alpha float8, beta float8, label text, init boolean, wfunc boolean)
RETURNS text AS $$
	import plpy
	import random
	import time

	class PLDA:
		"""Scalable and Parallel In-Database LDA"""
		def __init__(self, dataset, num_topic, num_iter, alpha, beta, label, init = True):
			plpy.info('constructing PLDA object...')
			label = label.replace('.', '_')
			self.dataset = dataset
			self.num_topic = num_topic
			self.num_iter = num_iter
			self.alpha = alpha
			self.beta = beta
			self.count_z = []
			self.vocab_size = 0

			if label.strip() != '':
				label = '_' + label.strip()
			self.doc_topic = 'doc_topic' + label
			self.word_topic = 'word_topic' + label
			self.pre_joined = 'pre_joined' + label
			
			self.init = init
			if self.init == True:
				plpy.execute('DROP TABLE IF EXISTS doc_word_topic_0')
				plpy.execute('CREATE TABLE doc_word_topic_0(docid int4, wordid int4, topics int4[])' \
					m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (docid)"'))
				plpy.execute('DROP TABLE IF EXISTS doc_word_topic_1')
				plpy.execute('CREATE TABLE doc_word_topic_1(docid int4, wordid int4, topics int4[])' \
					m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (docid)"'))
				plpy.execute('DROP TABLE IF EXISTS %s' % self.doc_topic)
				plpy.execute('CREATE TABLE %s(docid int4, topics int4[])' % (self.doc_topic) \
					m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (docid)"'))
				plpy.execute('DROP TABLE IF EXISTS %s' % (self.word_topic))
				plpy.execute('CREATE TABLE %s(wordid int4, topics int4[])' % (self.word_topic) \
					m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (wordid)"'))
				plpy.execute('DROP TABLE IF EXISTS %s' % (self.pre_joined))
				plpy.execute("""CREATE TEMP TABLE %s (docid int4, wordid int4, topics int4[],
					doc_topic int4[], word_topic int4[], corpus_topic int4[])""" % (self.pre_joined) \
					m4_ifdef(`__GREENPLUM__', `+ " WITH (APPENDONLY=TRUE,COMPRESSTYPE=QUICKLZ) DISTRIBUTED BY (docid)"'))

			plpy.info('counting size of vocabulary...')
			stime = time.time()
			voc_size_t = plpy.execute('SELECT max(wordid) + 1 voc_size FROM %s' % (self.dataset))
        		if (voc_size_t.nrows() <> 1):
				plpy.error("error: voc_size_t is not of the expected form")
			self.vocab_size = voc_size_t[0]['voc_size']
			etime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def init_random(self):
			stime = time.time()
			plpy.info('initializing topics randomly...')
			plpy.execute('TRUNCATE TABLE doc_word_topic_0');
			plpy.execute("""INSERT INTO doc_word_topic_0
				SELECT docid, wordid, MADLIB_SCHEMA.__newplda_random_assign(count, %d)
				FROM %s""" % (self.num_topic, self.dataset))
			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def comp_doc_topic(self, it):
			stime = time.time()
			plpy.info('\t\tcomputing per-document topic distribution...')
			plpy.execute('TRUNCATE TABLE %s' % (self.doc_topic))
			plpy.execute("""INSERT INTO %s
				SELECT docid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d)
				FROM doc_word_topic_%d
				GROUP BY docid""" % (self.doc_topic, self.num_topic, it % 2))
			etime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def comp_word_topic(self, it):
			stime = time.time()
			plpy.info('\t\tcomputing per-word topic distribution...')
			plpy.execute('TRUNCATE TABLE %s' % (self.word_topic))
			plpy.execute("""INSERT INTO %s
				SELECT wordid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d)
				FROM doc_word_topic_%d 
				GROUP BY wordid""" % (self.word_topic, self.num_topic, it % 2))
			etime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def comp_count_topic(self, it):
			stime = time.time()
			plpy.info('\t\tcomputing corpus-level topic distribution...')
			#str_sql = 'SELECT MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) topics FROM doc_word_topic_%d'
			#count_z_t = plpy.execute(str_sql % (self.num_topic, it % 2))
			# utilize the results of comp_doc_topic (if #docs < #words) or comp_word_topic(if #docs > #words) to speedup
			str_sql = 'SELECT sum(topics) topics FROM %s'
			count_z_t = plpy.execute(str_sql % (self.word_topic))
        		if (count_z_t.nrows() <> 1):
				plpy.error("error: count_z is not of the expected form")
			etime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (etime - stime))
			return count_z_t[0]['topics']

		def comp_ll(self):
			stime = time.time()
			plpy.info('\t\tcomputing log likelihood...')
			ll_d = plpy.execute("""SELECT MADLIB_SCHEMA.newplda_log_likelihood_agg(topics, %f) ll
				FROM %s""" % (self.alpha, self.doc_topic))
			ll_w = plpy.execute("""SELECT MADLIB_SCHEMA.newplda_log_likelihood_agg(topics, %f) ll
				FROM %s""" % (self.beta, self.word_topic))
        		if (ll_d.nrows() <> 1 or ll_w.nrows() <> 1):
				plpy.error('error: ll_d or ll_w is not of the expected form')
			etime = time.time()
			ll = ll_d[0]['ll'] + ll_w[0]['ll']
			plpy.info('\t\t\tLL=%.2f, time elapsed: %.2f seconds' % (ll, etime - stime))
			return ll

		def iteration_wfunc(self, it):  
			stime = time.time()
			plpy.info('iteration [%d]....' % (it))
			plpy.execute('TRUNCATE TABLE doc_word_topic_%d' % (it % 2))

			sstime = time.time()
			plpy.info('\t\tjoining tables...')
			plpy.execute('TRUNCATE TABLE %s' % (self.pre_joined))
			plpy.execute("""
				INSERT INTO %s
				SELECT dwz.docid, dwz.wordid, dwz.topics, dz.doc_topic, wz.word_topic, dz.corpus_topic
				FROM
				(
					SELECT docid, doc_topic, sum(doc_topic) OVER() corpus_topic
					FROM
					(
						SELECT docid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) doc_topic
						FROM doc_word_topic_%d 
						GROUP BY docid
					) t1
				) dz,
				(
					SELECT wordid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) word_topic
					FROM doc_word_topic_%d 
					GROUP BY wordid
				) wz,
				doc_word_topic_%d dwz
				WHERE dwz.docid = dz.docid AND dwz.wordid = wz.wordid
				""" % (self.pre_joined, self.num_topic, 1 - it % 2, self.num_topic, 1 - it % 2, 1 - it % 2))		
			eetime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (eetime - sstime))

			sstime = time.time()
			plpy.info('\t\tsampling new topics...')
			plpy.execute("""
				INSERT INTO doc_word_topic_%d
				SELECT triple[1] docid, triple[2] wordid, triple[3:array_upper(triple, 1)] topics
				FROM
				(
					SELECT 
						MADLIB_SCHEMA.__newplda_gibbs_wfunc_fast(jd.docid, jd.wordid, 
							jd.topics, jd.doc_topic, jd.word_topic, jd.corpus_topic, %f, %f, %d, %d)
						OVER (PARTITION BY jd.gp_segment_id ORDER BY jd.docid ROWS UNBOUNDED PRECEDING) triple
					FROM %s jd
				) t1 
				""" % (it % 2, self.alpha, self.beta, self.vocab_size, self.num_topic, self.pre_joined))
			eetime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (eetime - sstime))

			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def iteration_wfunc_v2(self, it):  
			stime = time.time()

			plpy.info('iteration [%d]....' % (it))
			plpy.info('\t\tjoining & sampling tables...')
			plpy.execute('TRUNCATE TABLE doc_word_topic_%d' % (it % 2))
			plpy.execute("""
				INSERT INTO doc_word_topic_%d
				SELECT triple[1] docid, triple[2] wordid, triple[3:array_upper(triple, 1)] topics
				FROM
				(
					SELECT 
						MADLIB_SCHEMA.__newplda_gibbs_wfunc_fast(jd.docid, jd.wordid, 
							jd.topics, jd.doc_topic, jd.word_topic, jd.corpus_topic::int4[], %f, %f, %d, %d)
						OVER (PARTITION BY jd.gp_segment_id ORDER BY jd.docid ROWS UNBOUNDED PRECEDING) triple
					FROM
					(
						SELECT dwz.gp_segment_id, dwz.docid, dwz.wordid, dwz.topics, dz.doc_topic, wz.word_topic, dz.corpus_topic
						FROM
						(
							SELECT docid, doc_topic, sum(doc_topic) OVER() corpus_topic
							FROM
							(
								SELECT docid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) doc_topic
								FROM doc_word_topic_%d 
								GROUP BY docid
							) t1
						) dz,
						(
							SELECT wordid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) word_topic
							FROM doc_word_topic_%d 
							GROUP BY wordid
						) wz,
						doc_word_topic_%d dwz
						WHERE dwz.docid = dz.docid AND dwz.wordid = wz.wordid
					) jd
				) t1
				""" % (it % 2, self.alpha, self.beta, self.vocab_size, self.num_topic, \
					self.num_topic, 1 - it % 2, self.num_topic, 1 - it % 2, 1 - it % 2))

			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def iteration_wfunc_v3(self, it):  
			stime = time.time()

			plpy.info('iteration [%d]....' % (it))
			plpy.info('\t\tjoining & sampling tables...')
			plpy.execute('TRUNCATE TABLE doc_word_topic_%d' % (it % 2))
			plpy.execute("""
				INSERT INTO doc_word_topic_%d
				SELECT triple[1] docid, triple[2] wordid, triple[3:array_upper(triple, 1)] topics
				FROM
				(
					SELECT 
						MADLIB_SCHEMA.__newplda_gibbs_wfunc_fast(jd.docid, jd.wordid, 
							jd.topics, jd.doc_topic, jd.word_topic, jd.corpus_topic::int4[], %f, %f, %d, %d)
						OVER (PARTITION BY jd.gp_segment_id ORDER BY jd.docid ROWS UNBOUNDED PRECEDING) triple
					FROM
					(
						SELECT dwz.gp_segment_id, dwz.docid, dwz.wordid, dwz.topics, dz.doc_topic, wz.word_topic, z.corpus_topic
						FROM
						(
							SELECT docid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) doc_topic
							FROM doc_word_topic_%d 
							GROUP BY docid
						) dz,
						(
							SELECT wordid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) word_topic
							FROM doc_word_topic_%d 
							GROUP BY wordid
						) wz,
						(
							SELECT MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) corpus_topic
							FROM doc_word_topic_%d 
						) z,
						doc_word_topic_%d dwz
						WHERE dwz.docid = dz.docid AND dwz.wordid = wz.wordid
					) jd
				) t1
				""" % (it % 2, self.alpha, self.beta, self.vocab_size, self.num_topic, \
					self.num_topic, 1 - it % 2, self.num_topic, 1 - it % 2, self.num_topic, 1 - it % 2, 1 - it % 2))

			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def run_wfunc(self):
			stime = time.time()
			if(self.init == True):
				self.init_random()
			plpy.info('start training process...')
			for it in range(1, self.num_iter + 1):
				self.iteration_wfunc_v3(it)
			self.comp_doc_topic(self.num_iter)
			self.comp_word_topic(self.num_iter)
			etime = time.time()
			plpy.info('finished, time elapsed: %.2f seconds' % (etime - stime))

		def iteration(self, it):  
			stime = time.time()
			plpy.info('iteration [%d]....' % (it))

			sstime = time.time()
			plpy.info('\t\tsampling new topics...')
			plpy.execute('TRUNCATE TABLE doc_word_topic_%d' % (it % 2))
			plpy.execute("""INSERT INTO doc_word_topic_%d
				SELECT dwz.docid, dwz.wordid,
					MADLIB_SCHEMA.__newplda_gibbs_sample(dwz.topics, dz.topics, wz.topics, array[%s], %f, %f)
				FROM doc_word_topic_%d AS dwz, %s AS dz, %s AS wz
				WHERE dwz.docid = dz.docid and dwz.wordid = wz.wordid""" % \
				(it % 2, str(self.count_z)[1:-1].replace('L', ''), self.alpha, \
				self.beta, 1 - it % 2, self.doc_topic, self.word_topic)) 
			
			eetime = time.time()
			plpy.info('\t\t\ttime elapsed: %.2f seconds' % (eetime - sstime))

			self.comp_doc_topic(it)
			self.comp_word_topic(it)
			self.count_z = self.comp_count_topic(it)

			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))

		def iteration_v2(self, it):  
			stime = time.time()

			plpy.info('iteration [%d]....' % (it))
			plpy.info('\t\tjoining & sampling tables...')
			plpy.execute('TRUNCATE TABLE doc_word_topic_%d' % (it % 2))
			plpy.execute("""
				INSERT INTO doc_word_topic_%d
				SELECT 
					docid, wordid, MADLIB_SCHEMA.__newplda_gibbs_sample(
						jd.topics, jd.doc_topic, jd.word_topic, jd.corpus_topic::int4[], %f, %f)
				FROM
				(
					SELECT dwz.gp_segment_id, dwz.docid, dwz.wordid, dwz.topics, dz.doc_topic, wz.word_topic, z.corpus_topic
					FROM
					(
						SELECT docid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) doc_topic
						FROM doc_word_topic_%d 
						GROUP BY docid
					) dz,
					(
						SELECT wordid, MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) word_topic
						FROM doc_word_topic_%d 
						GROUP BY wordid
					) wz,
					(
						SELECT MADLIB_SCHEMA.newplda_sum_topic_count_agg(topics, %d) corpus_topic
						FROM doc_word_topic_%d 
					) z,
					doc_word_topic_%d dwz
					WHERE dwz.docid = dz.docid AND dwz.wordid = wz.wordid
				) jd
				""" % (it % 2, self.alpha, self.beta, self.num_topic, 1 - it % 2, self.num_topic, 1 - it % 2, self.num_topic, 1 - it % 2, 1 - it % 2))

			etime = time.time()
			plpy.info('\t\ttime elapsed: %.2f seconds' % (etime - stime))

		
		def run(self):
			stime = time.time()
			if(self.init == True):
				self.init_random()

			self.comp_doc_topic(0)
			self.comp_word_topic(0)
			self.count_z = self.comp_count_topic(0)

			old_ll = self.comp_ll()

			plpy.info('start training process...')
			for it in range(1, self.num_iter + 1):
				self.iteration(it)
				cur_ll = self.comp_ll()
				diff_ll = cur_ll - old_ll
				old_ll = cur_ll
				plpy.info('diffLL = %.2f' % (diff_ll))
			
			etime = time.time()
			plpy.info('finished, time elapsed: %.2f seconds' % (etime - stime))

		def run_v2(self):
			stime = time.time()
			if(self.init == True):
				self.init_random()

			plpy.info('start training process...')
			for it in range(1, self.num_iter + 1):
				self.iteration_v2(it)

			self.comp_doc_topic(self.num_iter)
			self.comp_word_topic(self.num_iter)
			
			etime = time.time()
			plpy.info('finished, time elapsed: %.2f seconds' % (etime - stime))

	plda = PLDA(dataset, num_topic, num_iter, alpha, beta, label, init)
	if wfunc:
		plda.run_wfunc()
	else:
		plda.run_v2()
	return 'succeeds';
$$ LANGUAGE plpythonu;
